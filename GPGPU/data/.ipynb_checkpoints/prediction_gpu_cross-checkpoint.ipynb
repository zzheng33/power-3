{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8899c483-e062-43b8-8b3b-2aaf9fe27dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate,LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.layers import Add, LeakyReLU\n",
    "from scipy import stats\n",
    "from tensorflow.keras.activations import relu\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb285c5d-2937-4201-9ea1-f4d21c9e737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Step 1: Data Preprocessing ############################# \n",
    "\n",
    "# Define directories for training and validation data\n",
    "train_dir = \"./altis_power_cap_res/runs/train\"\n",
    "validation_dirs = [\n",
    "    \"./A30/hec_power_cap_res/runs/validation\",\n",
    "    # \"./A30/altis_power_cap_res/runs/validation\",\n",
    "    # \"./A30/ecp_power_cap_res/runs/validation\"\n",
    "    # \"./V100/altis_power_cap_res/runs/validation\",\n",
    "    # \"./V100/ecp_power_cap_res/runs/validation\"\n",
    "]\n",
    "\n",
    "save_model_dir = \"./MLP_model/gpu_model/\"\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "# Load CSV files from train directory\n",
    "train_csv_files = [f for f in os.listdir(train_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "# Load and merge training data while filtering out specified CPU power caps\n",
    "train_data = []\n",
    "for file in train_csv_files:\n",
    "    file_path = os.path.join(train_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Optional: Drop rows with specific CPU Power Cap values\n",
    "    # df = df[~df[\"CPU Power Cap\"].isin([220, 240, 260])]\n",
    "\n",
    "    train_data.append(df)\n",
    "\n",
    "# Merge all training data\n",
    "train_df = pd.concat(train_data, ignore_index=True)\n",
    "\n",
    "# Load validation data from multiple directories\n",
    "validation_data = {}\n",
    "for vdir in validation_dirs:\n",
    "    validation_csv_files = [f for f in os.listdir(vdir) if f.endswith(\".csv\")]\n",
    "    for file in validation_csv_files:\n",
    "        file_path = os.path.join(vdir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop unwanted GPU Power Cap values\n",
    "        df = df[~df[\"GPU Power Cap\"].isin([123])]\n",
    "\n",
    "        # Reset index to maintain row-order alignment\n",
    "        df = df.sort_values(by=[\"CPU Power Cap\", \"GPU Power Cap\"]).reset_index(drop=True)\n",
    "\n",
    "        validation_data[file] = df\n",
    "\n",
    "# Drop any rows with missing values\n",
    "train_df.dropna(inplace=True)\n",
    "for key in validation_data:\n",
    "    validation_data[key].dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e27df1e4-298b-406d-97fe-f588b210b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Step 2: Build MLP Model ############################# \n",
    "\n",
    "cpu_cap_min = 140\n",
    "cpu_cap_max = 200\n",
    "\n",
    "gpu_cap_min = 150  \n",
    "gpu_cap_max = 250\n",
    "\n",
    "train_df[\"CPU Power Cap\"] = (train_df[\"CPU Power Cap\"] - cpu_cap_min) / (cpu_cap_max - cpu_cap_min)\n",
    "train_df[\"GPU Power Cap\"] = (train_df[\"GPU Power Cap\"] - gpu_cap_min) / (gpu_cap_max - gpu_cap_min)\n",
    "\n",
    "# === Use normalized power caps directly in feature set ===\n",
    "feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "# feature_cols = [\"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "target_col = \"Performance\"\n",
    "\n",
    "# Extract features and target\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize full feature matrix (if needed for other features)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "\n",
    "# Build the improved MLP model\n",
    "# Define the MLP model properly\n",
    "# gpu: relu x2, selu x2\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(X_train_scaled.shape[1],)),  # Explicitly define input shape\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='selu'),\n",
    "    Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258a5143-f2a5-4789-b897-efce63627c75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748479502.878158 2264501 service.cc:152] XLA service 0x7f9714020ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748479502.878203 2264501 service.cc:160]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1748479503.148075 2264501 cuda_dnn.cc:529] Loaded cuDNN version 91001\n",
      "I0000 00:00:1748479505.565243 2264501 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "############################# Step 3: Train MLP Model #############################\n",
    "# Compile the model with a different optimizer\n",
    "model.compile(optimizer='nadam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=3)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(os.path.join(save_model_dir, \"performance_prediction_model_gpu_cross.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d68f7644-69fc-41f7-a998-72e5c118f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "############################# Step 5: Populate Initial Performance Matrix ############################# \n",
    "\n",
    "# === Parameters === #\n",
    "cpu_cap_min = 140\n",
    "cpu_cap_max = 200\n",
    "\n",
    "\n",
    "gpu_cap_min_train = 150  # A100\n",
    "gpu_cap_max_train = 250\n",
    "\n",
    "# Predefined A100-normalized GPU cap values\n",
    "a100_normalized_values = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# === Model and Features === #\n",
    "model_path = os.path.join(save_model_dir, \"performance_prediction_model_gpu.h5\")\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
    "\n",
    "feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "# feature_cols =  [\"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "target_col = \"Performance\"\n",
    "\n",
    "\n",
    "# === Step 5: Normalize and Build Dense Matrix from A100 === #\n",
    "app_data = {}\n",
    "all_power_pairs = set()\n",
    "\n",
    "for file in train_csv_files:\n",
    "    file_path = os.path.join(train_dir, file)\n",
    "    app_name = file.replace(\"_performance.csv\", \"\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    # df = df[[\"CPU Power Cap\", \"GPU Power Cap\", \"Performance\"]]\n",
    "\n",
    "    # Normalize CPU and GPU power caps\n",
    "    df[\"Normalized CPU Cap\"] = (df[\"CPU Power Cap\"] - cpu_cap_min) / (cpu_cap_max - cpu_cap_min)\n",
    "\n",
    "    df[\"Temp Norm GPU Cap\"] = (df[\"GPU Power Cap\"] - gpu_cap_min_train) / (gpu_cap_max_train - gpu_cap_min_train)\n",
    "    df[\"Normalized GPU Cap\"] = df[\"Temp Norm GPU Cap\"].apply(lambda x: float(a100_normalized_values[np.argmin(np.abs(a100_normalized_values - x))]))\n",
    "\n",
    "\n",
    "    # Create normalized power pair index\n",
    "    df[\"Power Pair\"] = list(zip(df[\"Normalized CPU Cap\"].round(4), df[\"Normalized GPU Cap\"].round(4)))\n",
    "\n",
    "    # Save power pairs\n",
    "    all_power_pairs.update(df[\"Power Pair\"].values)\n",
    "\n",
    "    # Store performance under normalized pair index\n",
    "    app_data[app_name] = df[[\"Power Pair\", \"Performance\"]].set_index(\"Power Pair\")\n",
    "\n",
    "# Create initial performance matrix with all normalized power pairs\n",
    "all_power_pairs = sorted(all_power_pairs)\n",
    "performance_matrix = pd.DataFrame(index=all_power_pairs, columns=sorted(app_data.keys()))\n",
    "\n",
    "for app_name, df in app_data.items():\n",
    "    performance_matrix[app_name] = df[\"Performance\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b353b99-0006-4481-b020-5e87b0c3b361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Neural Network Prediction for knn:\n",
      "  Prediction Accuracy: 95.17%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Neural Network Prediction for stencil3d:\n",
      "  Prediction Accuracy: 35.86%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Neural Network Prediction for extrema:\n",
      "  Prediction Accuracy: 96.86%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Neural Network Prediction for aobench:\n",
      "  Prediction Accuracy: 96.74%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Neural Network Prediction for softmax:\n",
      "  Prediction Accuracy: 96.47%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Neural Network Prediction for convolution3D:\n",
      "  Prediction Accuracy: 96.77%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Neural Network Prediction for chacha20:\n",
      "  Prediction Accuracy: 96.82%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Neural Network Prediction for addBiasResidualLayerNorm:\n",
      "  Prediction Accuracy: 98.14%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Neural Network Prediction for kalman:\n",
      "  Prediction Accuracy: 94.10%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Neural Network Prediction for background-subtract:\n",
      "  Prediction Accuracy: 98.84%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Neural Network Prediction for zmddft:\n",
      "  Prediction Accuracy: 95.10%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################  Evaluate MLP Model Performance ############################# \n",
    "\n",
    "# Define model path and load trained model\n",
    "model_path = os.path.join(save_model_dir, \"performance_prediction_model_gpu.h5\")\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
    "\n",
    "# Loop over preprocessed validation data\n",
    "for file, df_new in validation_data.items():\n",
    "    new_app_name = file.replace(\"_performance.csv\", \"\")\n",
    "\n",
    "    # df_new = df_new.sort_values(by=[\"CPU Power Cap\", \"GPU Power Cap\"]).reset_index(drop=True)\n",
    "\n",
    "    # Assign normalized power pair index from A100 training matrix\n",
    "    df_new[\"Power Pair\"] = list(performance_matrix.index)\n",
    "    df_new[\"CPU Power Cap\"] = [pair[0] for pair in df_new[\"Power Pair\"]]\n",
    "    df_new[\"GPU Power Cap\"] = [pair[1] for pair in df_new[\"Power Pair\"]]\n",
    "\n",
    "\n",
    "    # Sample 20% of power pairs\n",
    "    df_sampled = df_new.sample(frac=0.1, random_state=seed)\n",
    "    sampled_pairs = df_sampled[\"Power Pair\"].unique()\n",
    "\n",
    "    true_values, nn_predicted_values, accuracy_values = [], [], []\n",
    "\n",
    "    for power_pair in sampled_pairs:\n",
    "        X_sample = df_new[df_new[\"Power Pair\"] == power_pair][feature_cols].values\n",
    "\n",
    "        # Normalize features using same scaler as training\n",
    "        X_sample_scaled = scaler_X.transform(X_sample)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_sample_scaled)\n",
    "        predicted_value = scaler_y.inverse_transform(y_pred)[0][0]\n",
    "\n",
    "        # Ground truth\n",
    "        true_value = df_new.loc[df_new[\"Power Pair\"] == power_pair, \"Performance\"].values[0]\n",
    "        true_values.append(true_value)\n",
    "        nn_predicted_values.append(predicted_value)\n",
    "\n",
    "        # Accuracy\n",
    "        accuracy = 100 - (abs(true_value - predicted_value) / true_value * 100)\n",
    "        accuracy_values.append(accuracy)\n",
    "\n",
    "    # Metrics\n",
    "    nn_mae = mean_absolute_error(true_values, nn_predicted_values)\n",
    "    nn_rmse = np.sqrt(mean_squared_error(true_values, nn_predicted_values))\n",
    "    nn_r2 = r2_score(true_values, nn_predicted_values)\n",
    "    avg_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "    # Output\n",
    "    print(f\"Neural Network Prediction for {new_app_name}:\")\n",
    "    print(f\"  Prediction Accuracy: {avg_accuracy:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d02fa533-9698-47b7-a65b-ee0cbdc1b17d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "NN Prediction for stencil3d: MAE=0.0576, Prediction Accuracy=92.41%\n",
      "Epoch 1/25\n",
      "Epoch 2/25\n",
      "Epoch 3/25\n",
      "Epoch 4/25\n",
      "Epoch 5/25\n",
      "Epoch 6/25\n",
      "Epoch 7/25\n",
      "Epoch 8/25\n",
      "Epoch 9/25\n",
      "Epoch 10/25\n",
      "Epoch 11/25\n",
      "Epoch 12/25\n",
      "Epoch 13/25\n",
      "Epoch 14/25\n",
      "Epoch 15/25\n",
      "Epoch 16/25\n",
      "Epoch 17/25\n",
      "Epoch 18/25\n",
      "Epoch 19/25\n",
      "Epoch 20/25\n",
      "Epoch 21/25\n",
      "Epoch 22/25\n",
      "Epoch 23/25\n",
      "Epoch 24/25\n",
      "Epoch 25/25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "NCF Prediction for stencil3d: MAE=0.0977, Prediction Accuracy=86.62%\n"
     ]
    }
   ],
   "source": [
    "# === Step 6: Add Validation Data from A30 === #\n",
    "nn_results = []\n",
    "cf_results = []\n",
    "\n",
    "for file, df_new in validation_data.items():\n",
    "    \n",
    "    new_app_name = file.replace(\"_performance.csv\", \"\")\n",
    "\n",
    "    # Sort to ensure order aligns with A100 performance_matrix index\n",
    "    # df_new = df_new.sort_values(by=[\"CPU Power Cap\", \"GPU Power Cap\"]).reset_index(drop=True)\n",
    "\n",
    "    # Replace the Power Pair with ordered normalized index from A100 matrix\n",
    "    df_new[\"Power Pair\"] = list(performance_matrix.index)\n",
    "\n",
    "    # Split normalized (cpu, gpu) values back into columns\n",
    "    df_new[\"CPU Power Cap\"] = [pair[0] for pair in df_new[\"Power Pair\"]]\n",
    "    df_new[\"GPU Power Cap\"] = [pair[1] for pair in df_new[\"Power Pair\"]]\n",
    "    \n",
    "\n",
    "    # Initialize column for the new app in the performance matrix\n",
    "    performance_matrix[new_app_name] = np.nan\n",
    "\n",
    "\n",
    "    #############  Predict 20% of power pairs using trained NN --- Construct Sparse Matrix  ############# \n",
    "    \n",
    "    # df_sampled = df_new.sample(frac=0.2, random_state=seed)  # Select 20% of rows\n",
    "    df_sampled = df_new.sample(n=8, random_state=seed)\n",
    "    \n",
    "    sampled_pairs = df_sampled[\"Power Pair\"].unique()\n",
    "\n",
    "    true_values, nn_predicted_values = [], []\n",
    "    for power_pair in sampled_pairs:\n",
    "        X_sample = df_new[df_new[\"Power Pair\"] == power_pair][feature_cols].values\n",
    "        X_sample_scaled = scaler_X.transform(X_sample)\n",
    "        \n",
    "        # Predict performance\n",
    "        y_pred = model.predict(X_sample_scaled)\n",
    "        predicted_value = scaler_y.inverse_transform(y_pred)[0][0]\n",
    "    \n",
    "        # Fill performance matrix with NN predictions\n",
    "        performance_matrix.at[power_pair, new_app_name] = predicted_value\n",
    "\n",
    "        # Store true and predicted values for error calculation\n",
    "        if power_pair in df_new.set_index(\"Power Pair\").index:\n",
    "            actual = df_new.loc[df_new[\"Power Pair\"] == power_pair, \"Performance\"].values[0]\n",
    "            true_values.append(actual)\n",
    "            nn_predicted_values.append(predicted_value)\n",
    "    \n",
    "    ############## Compute NN Prediction Accuracy ##############\n",
    "\n",
    "    true_values = np.array(true_values)\n",
    "    nn_predicted_values = np.array(nn_predicted_values)\n",
    "    \n",
    "    nn_mae = mean_absolute_error(true_values, nn_predicted_values)\n",
    "    nn_rmse = np.sqrt(mean_squared_error(true_values, nn_predicted_values))\n",
    "    nn_r2 = r2_score(true_values, nn_predicted_values)\n",
    "    \n",
    "    # Percentage-Based Prediction Error\n",
    "    relative_errors = np.abs((true_values - nn_predicted_values) / true_values) * 100\n",
    "    nn_pred_error = np.mean(relative_errors)\n",
    "    \n",
    "    # 95% Confidence Interval for Prediction Accuracy\n",
    "    confidence = 0.98\n",
    "    n = len(relative_errors)\n",
    "    std_err = stats.sem(relative_errors)  # Standard error of the mean\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2., n-1)  # Margin of error\n",
    "    \n",
    "    # The accuracy is (100 - pred_error)\n",
    "    nn_accuracy = 100 - nn_pred_error\n",
    "    nn_accuracy_ci_low = nn_accuracy - h\n",
    "    nn_accuracy_ci_high = nn_accuracy + h\n",
    "    \n",
    "    # Save results, now including CI\n",
    "    nn_results.append((new_app_name, nn_mae, nn_rmse, nn_r2, nn_pred_error, nn_accuracy_ci_low, nn_accuracy_ci_high))\n",
    "\n",
    "    print(f\"NN Prediction for {new_app_name}: MAE={nn_mae:.4f}, Prediction Accuracy={100 - nn_pred_error:.2f}%\")\n",
    "\n",
    "    ##############  Train Neural CF  ##############\n",
    "    power_pair_map = {pair: i for i, pair in enumerate(performance_matrix.index)}\n",
    "    app_map = {app: i for i, app in enumerate(performance_matrix.columns)}\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for app in performance_matrix.columns:\n",
    "        for power_pair in performance_matrix.index:\n",
    "            if not np.isnan(performance_matrix.at[power_pair, app]):\n",
    "                train_data.append([power_pair_map[power_pair], app_map[app]])\n",
    "                train_labels.append(performance_matrix.at[power_pair, app])\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Define Neural CF Model\n",
    "    num_power_pairs = len(power_pair_map)\n",
    "    num_apps = len(app_map)\n",
    "    latent_dim = 10  # Embedding size\n",
    "\n",
    "    input_power_pair = Input(shape=(1,))\n",
    "    input_app = Input(shape=(1,))\n",
    "\n",
    "    power_embedding = Embedding(num_power_pairs, latent_dim)(input_power_pair)\n",
    "    app_embedding = Embedding(num_apps, latent_dim)(input_app)\n",
    "\n",
    "    power_vec = Flatten()(power_embedding)\n",
    "    app_vec = Flatten()(app_embedding)\n",
    "    merged = Concatenate()([power_vec, app_vec])\n",
    "\n",
    "    dense_0 = Dense(256, activation='relu')(merged)\n",
    "    dense_1 = Dense(128, activation='relu')(dense_0)\n",
    "    dense_2 = Dense(64, activation='selu')(dense_1)\n",
    "    dense_3 = Dense(32, activation='selu')(dense_2)\n",
    "    \n",
    "    output = Dense(1, activation='linear')(dense_3)\n",
    "\n",
    "    ncf_model = Model(inputs=[input_power_pair, input_app], outputs=output)\n",
    "    ncf_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    ncf_model.fit([train_data[:, 0], train_data[:, 1]], train_labels, epochs=25, batch_size=32, verbose=3)\n",
    "\n",
    "    ##############  Predict Missing Value via NCF  ##############\n",
    "    for power_pair in performance_matrix.index:\n",
    "        if np.isnan(performance_matrix.at[power_pair, new_app_name]):\n",
    "            power_idx = power_pair_map[power_pair]\n",
    "            app_idx = app_map[new_app_name]\n",
    "            pred_value = ncf_model.predict([np.array([power_idx]), np.array([app_idx])])[0][0]\n",
    "            performance_matrix.at[power_pair, new_app_name] = pred_value\n",
    "\n",
    "    ############### Compute CF Prediction Accuracy ##############\n",
    "    true_values = df_new.set_index(\"Power Pair\")[\"Performance\"]\n",
    "    predicted_values = performance_matrix[new_app_name].reindex(true_values.index)\n",
    "    \n",
    "    cf_mae = mean_absolute_error(true_values, predicted_values)\n",
    "    cf_rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "    cf_r2 = r2_score(true_values, predicted_values)\n",
    "    \n",
    "    # Percentage-Based Prediction Error\n",
    "    relative_errors = np.abs((true_values - predicted_values) / true_values) * 100\n",
    "    cf_pred_error = np.mean(relative_errors)\n",
    "    \n",
    "    # 95% Confidence Interval for Prediction Accuracy\n",
    "    \n",
    "    n = len(relative_errors)\n",
    "    std_err = stats.sem(relative_errors)  # Standard error of the mean\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2., n-1)  # Margin of error\n",
    "    \n",
    "    # The accuracy is (100 - pred_error)\n",
    "    cf_accuracy = 100 - cf_pred_error\n",
    "    cf_accuracy_ci_low = cf_accuracy - h\n",
    "    cf_accuracy_ci_high = cf_accuracy + h\n",
    "    \n",
    "    # Save results including CI\n",
    "    cf_results.append((new_app_name, cf_mae, cf_rmse, cf_r2, cf_pred_error, cf_accuracy_ci_low, cf_accuracy_ci_high))\n",
    "\n",
    "    print(f\"NCF Prediction for {new_app_name}: MAE={cf_mae:.4f}, Prediction Accuracy={100 - cf_pred_error:.2f}%\")\n",
    "\n",
    "# Convert results into a DataFrame and display\n",
    "nn_results_df = pd.DataFrame(nn_results, columns=[\"Application\", \"MAE\", \"RMSE\", \"R²\", \"Prediction Error (%)\", \"low\",\"high\"])\n",
    "cf_results_df = pd.DataFrame(cf_results, columns=[\"Application\", \"MAE\", \"RMSE\", \"R²\", \"Prediction Error (%)\",\"low\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f7789aa-acab-446b-8d3d-70cf52169e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction Accuracy Comparison (MLP vs. NCF) with 98% Confidence Interval ===\n",
      "Application     MLP Accuracy (%)          NCF Accuracy (%)         \n",
      "----------------------------------------------------------------------\n",
      "stencil3d       92.41% [78.16%, 106.66%]  86.62% [82.87%, 90.37%]  \n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n=== Prediction Accuracy Comparison (MLP vs. NCF) ===\")\n",
    "# print(f\"{'Application':<15} {'MLP Accuracy (%)':<20} {'NCF Accuracy (%)':<20}\")\n",
    "# print(\"-\" * 55)\n",
    "\n",
    "# for (app_nn, _, _, _, pred_error_nn), (app_cf, _, _, _, pred_error_cf) in zip(nn_results, cf_results):\n",
    "#     assert app_nn == app_cf, f\"App mismatch: {app_nn} vs {app_cf}\"\n",
    "#     mlp_acc = 100 - pred_error_nn\n",
    "#     ncf_acc = 100 - pred_error_cf\n",
    "#     print(f\"{app_nn:<15} {mlp_acc:<20.2f} {ncf_acc:<20.2f}\")\n",
    "\n",
    "print(\"\\n=== Prediction Accuracy Comparison (MLP vs. NCF) with 98% Confidence Interval ===\")\n",
    "print(f\"{'Application':<15} {'MLP Accuracy (%)':<25} {'NCF Accuracy (%)':<25}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for (app_nn, _, _, _, pred_error_nn, ci_low_nn, ci_high_nn), (app_cf, _, _, _, pred_error_cf, ci_low_cf, ci_high_cf) in zip(nn_results, cf_results):\n",
    "    assert app_nn == app_cf, f\"App mismatch: {app_nn} vs {app_cf}\"\n",
    "    mlp_acc = 100 - pred_error_nn\n",
    "    ncf_acc = 100 - pred_error_cf\n",
    "\n",
    "    mlp_str = f\"{mlp_acc:.2f}% [{ci_low_nn:.2f}%, {ci_high_nn:.2f}%]\"\n",
    "    ncf_str = f\"{ncf_acc:.2f}% [{ci_low_cf:.2f}%, {ci_high_cf:.2f}%]\"\n",
    "    \n",
    "    print(f\"{app_nn:<15} {mlp_str:<25} {ncf_str:<25}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4687612-0219-4644-a87a-50f9cb416fae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bfs</th>\n",
       "      <th>cfd</th>\n",
       "      <th>cfd_double</th>\n",
       "      <th>fdtd2d</th>\n",
       "      <th>gemm</th>\n",
       "      <th>gups</th>\n",
       "      <th>kmeans</th>\n",
       "      <th>lavamd</th>\n",
       "      <th>maxflops</th>\n",
       "      <th>nw</th>\n",
       "      <th>...</th>\n",
       "      <th>Resnet50</th>\n",
       "      <th>sw4lite</th>\n",
       "      <th>Laghos</th>\n",
       "      <th>NAMD</th>\n",
       "      <th>miniGAN</th>\n",
       "      <th>gromacs</th>\n",
       "      <th>bert_large</th>\n",
       "      <th>UNet</th>\n",
       "      <th>CRADL</th>\n",
       "      <th>XSBench</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(120, 150)</th>\n",
       "      <td>0.637024</td>\n",
       "      <td>0.637359</td>\n",
       "      <td>0.818064</td>\n",
       "      <td>0.733109</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.970849</td>\n",
       "      <td>0.899788</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.716044</td>\n",
       "      <td>0.615326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748207</td>\n",
       "      <td>0.593205</td>\n",
       "      <td>0.645191</td>\n",
       "      <td>0.620911</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.684636</td>\n",
       "      <td>0.806175</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>0.640825</td>\n",
       "      <td>0.581656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 160)</th>\n",
       "      <td>0.601343</td>\n",
       "      <td>0.630359</td>\n",
       "      <td>0.843605</td>\n",
       "      <td>0.785478</td>\n",
       "      <td>0.636686</td>\n",
       "      <td>0.985136</td>\n",
       "      <td>0.899804</td>\n",
       "      <td>0.671545</td>\n",
       "      <td>0.753145</td>\n",
       "      <td>0.634912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>0.579719</td>\n",
       "      <td>0.640847</td>\n",
       "      <td>0.611251</td>\n",
       "      <td>0.696895</td>\n",
       "      <td>0.690649</td>\n",
       "      <td>0.823847</td>\n",
       "      <td>0.692480</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.594419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 170)</th>\n",
       "      <td>0.637012</td>\n",
       "      <td>0.630417</td>\n",
       "      <td>0.843523</td>\n",
       "      <td>0.845871</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>0.985148</td>\n",
       "      <td>0.918240</td>\n",
       "      <td>0.656853</td>\n",
       "      <td>0.773292</td>\n",
       "      <td>0.624922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756815</td>\n",
       "      <td>0.594429</td>\n",
       "      <td>0.642583</td>\n",
       "      <td>0.613256</td>\n",
       "      <td>0.725310</td>\n",
       "      <td>0.703670</td>\n",
       "      <td>0.829256</td>\n",
       "      <td>0.704401</td>\n",
       "      <td>0.640516</td>\n",
       "      <td>0.590241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 180)</th>\n",
       "      <td>0.632312</td>\n",
       "      <td>0.630321</td>\n",
       "      <td>0.870889</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>0.644969</td>\n",
       "      <td>0.985232</td>\n",
       "      <td>0.918253</td>\n",
       "      <td>0.633694</td>\n",
       "      <td>0.743598</td>\n",
       "      <td>0.615301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761961</td>\n",
       "      <td>0.588311</td>\n",
       "      <td>0.640753</td>\n",
       "      <td>0.590209</td>\n",
       "      <td>0.728197</td>\n",
       "      <td>0.712597</td>\n",
       "      <td>0.847633</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>0.640477</td>\n",
       "      <td>0.570782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 190)</th>\n",
       "      <td>0.637010</td>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.870746</td>\n",
       "      <td>0.916513</td>\n",
       "      <td>0.642902</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.918217</td>\n",
       "      <td>0.666623</td>\n",
       "      <td>0.743510</td>\n",
       "      <td>0.624946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757247</td>\n",
       "      <td>0.599265</td>\n",
       "      <td>0.646845</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.741272</td>\n",
       "      <td>0.717044</td>\n",
       "      <td>0.858999</td>\n",
       "      <td>0.712057</td>\n",
       "      <td>0.634252</td>\n",
       "      <td>0.559531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 210)</th>\n",
       "      <td>0.988398</td>\n",
       "      <td>0.983083</td>\n",
       "      <td>0.964160</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.970615</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984617</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>1.012247</td>\n",
       "      <td>0.991432</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>0.984795</td>\n",
       "      <td>0.977278</td>\n",
       "      <td>0.963588</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.978682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 220)</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.983148</td>\n",
       "      <td>0.964155</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>0.990035</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.978321</td>\n",
       "      <td>0.983114</td>\n",
       "      <td>0.975661</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002311</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.983839</td>\n",
       "      <td>0.953184</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>0.968834</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>0.962764</td>\n",
       "      <td>0.927079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 230)</th>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964168</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.995034</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.966676</td>\n",
       "      <td>0.975567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997511</td>\n",
       "      <td>0.922074</td>\n",
       "      <td>0.982641</td>\n",
       "      <td>0.952342</td>\n",
       "      <td>0.973780</td>\n",
       "      <td>0.964614</td>\n",
       "      <td>0.971409</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>0.948404</td>\n",
       "      <td>0.915300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 240)</th>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.983124</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.989992</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.983013</td>\n",
       "      <td>0.869468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986865</td>\n",
       "      <td>0.953991</td>\n",
       "      <td>1.009568</td>\n",
       "      <td>0.992875</td>\n",
       "      <td>0.950191</td>\n",
       "      <td>0.962752</td>\n",
       "      <td>0.976246</td>\n",
       "      <td>0.978114</td>\n",
       "      <td>0.947420</td>\n",
       "      <td>0.981660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 250)</th>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.983044</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>0.985166</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.966643</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998861</td>\n",
       "      <td>0.905228</td>\n",
       "      <td>0.980246</td>\n",
       "      <td>0.941115</td>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.957326</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.963974</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.917863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bfs       cfd  cfd_double    fdtd2d      gemm      gups  \\\n",
       "(120, 150)  0.637024  0.637359    0.818064  0.733109  0.638716  0.970849   \n",
       "(120, 160)  0.601343  0.630359    0.843605  0.785478  0.636686  0.985136   \n",
       "(120, 170)  0.637012  0.630417    0.843523  0.845871  0.642886  0.985148   \n",
       "(120, 180)  0.632312  0.630321    0.870889  0.879836  0.644969  0.985232   \n",
       "(120, 190)  0.637010  0.630438    0.870746  0.916513  0.642902  0.999798   \n",
       "...              ...       ...         ...       ...       ...       ...   \n",
       "(200, 210)  0.988398  0.983083    0.964160  0.999803  0.970615  0.999860   \n",
       "(200, 220)  0.999967  0.983148    0.964155  0.999816  0.990035  0.999869   \n",
       "(200, 230)  0.999982  1.000000    0.964168  0.999852  0.995034  0.999899   \n",
       "(200, 240)  0.999965  0.983124    0.999882  0.999814  0.989992  0.999878   \n",
       "(200, 250)  0.988516  0.983044    0.999986  0.999803  0.990102  0.985166   \n",
       "\n",
       "              kmeans    lavamd  maxflops        nw  ...  Resnet50   sw4lite  \\\n",
       "(120, 150)  0.899788  0.656863  0.716044  0.615326  ...  0.748207  0.593205   \n",
       "(120, 160)  0.899804  0.671545  0.753145  0.634912  ...  0.763345  0.579719   \n",
       "(120, 170)  0.918240  0.656853  0.773292  0.624922  ...  0.756815  0.594429   \n",
       "(120, 180)  0.918253  0.633694  0.743598  0.615301  ...  0.761961  0.588311   \n",
       "(120, 190)  0.918217  0.666623  0.743510  0.624946  ...  0.757247  0.599265   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "(200, 210)  0.999771  0.999971  1.000000  0.999959  ...  0.984617  0.986726   \n",
       "(200, 220)  0.999768  0.978321  0.983114  0.975661  ...  1.002311  0.945251   \n",
       "(200, 230)  1.000000  0.999954  0.966676  0.975567  ...  0.997511  0.922074   \n",
       "(200, 240)  0.999878  0.988977  0.983013  0.869468  ...  0.986865  0.953991   \n",
       "(200, 250)  0.999806  0.988977  0.966643  0.952318  ...  0.998861  0.905228   \n",
       "\n",
       "              Laghos      NAMD   miniGAN   gromacs  bert_large      UNet  \\\n",
       "(120, 150)  0.645191  0.620911  0.679260  0.684636    0.806175  0.686133   \n",
       "(120, 160)  0.640847  0.611251  0.696895  0.690649    0.823847  0.692480   \n",
       "(120, 170)  0.642583  0.613256  0.725310  0.703670    0.829256  0.704401   \n",
       "(120, 180)  0.640753  0.590209  0.728197  0.712597    0.847633  0.714047   \n",
       "(120, 190)  0.646845  0.587302  0.741272  0.717044    0.858999  0.712057   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "(200, 210)  1.012247  0.991432  0.990818  0.984795    0.977278  0.963588   \n",
       "(200, 220)  0.983839  0.953184  0.972923  0.968834    0.973787  0.963600   \n",
       "(200, 230)  0.982641  0.952342  0.973780  0.964614    0.971409  0.946061   \n",
       "(200, 240)  1.009568  0.992875  0.950191  0.962752    0.976246  0.978114   \n",
       "(200, 250)  0.980246  0.941115  0.938624  0.957326    0.971000  0.963974   \n",
       "\n",
       "               CRADL   XSBench  \n",
       "(120, 150)  0.640825  0.581656  \n",
       "(120, 160)  0.634400  0.594419  \n",
       "(120, 170)  0.640516  0.590241  \n",
       "(120, 180)  0.640477  0.570782  \n",
       "(120, 190)  0.634252  0.559531  \n",
       "...              ...       ...  \n",
       "(200, 210)  0.982609  0.978682  \n",
       "(200, 220)  0.962764  0.927079  \n",
       "(200, 230)  0.948404  0.915300  \n",
       "(200, 240)  0.947420  0.981660  \n",
       "(200, 250)  0.959275  0.917863  \n",
       "\n",
       "[99 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0284b39c-2cd1-4d1a-abd2-2a4495869e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix.to_csv(\"./prediction_res/performance_matrix_gpu_hec_a30_3d.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f00961f2-b11c-43c1-a05a-a615d80c6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix.to_csv(\"./prediction_res/performance_matrix_gpu_altis_a30.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8135c1eb-efab-4315-bbc2-a5a0a3ec1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix.to_csv(\"./prediction_res/performance_matrix_gpu_ecp_a30.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de323050-07e4-4eb3-a750-eb586fe2b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix.to_csv(\"./prediction_res/performance_matrix_gpu_ecp_a30_2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac57f61-2383-43a4-9ffa-367f240ed237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
