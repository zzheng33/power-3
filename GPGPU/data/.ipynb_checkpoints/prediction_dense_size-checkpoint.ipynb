{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8899c483-e062-43b8-8b3b-2aaf9fe27dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 03:00:43.966534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745550043.982510 1373292 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745550043.987303 1373292 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745550043.999340 1373292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745550043.999355 1373292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745550043.999356 1373292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745550043.999357 1373292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.layers import Add, LeakyReLU\n",
    "from scipy import stats\n",
    "import random\n",
    "from tensorflow.keras.activations import relu\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27df1e4-298b-406d-97fe-f588b210b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(num, app):\n",
    "    ############################# Step 1: Data Preprocessing ############################# \n",
    "    \n",
    "    # Define directories for training and validation data\n",
    "    train_dir = \"./altis_power_cap_res/runs/train\"\n",
    "    validation_dir = \"./ecp_power_cap_res/runs/validation\"\n",
    "    \n",
    "    # train_dir = \"./npb_power_cap_res/runs/train\"\n",
    "    # validation_dir = \"./npb_power_cap_res/runs/validation\"\n",
    "    \n",
    "    save_model_dir = \"./MLP_model/gpu_model/arxiv/\"\n",
    "    os.makedirs(save_model_dir, exist_ok=True)\n",
    "    \n",
    "    # Load CSV files from train directory\n",
    "    train_csv_files = [f for f in os.listdir(train_dir) if f.endswith(\".csv\")]\n",
    "    validation_csv_files = [f for f in os.listdir(validation_dir) if f.endswith(\".csv\") and app.lower() in f.lower()]\n",
    "\n",
    "    \n",
    "    # Load and merge training data while filtering out specified CPU power caps\n",
    "    train_data = []\n",
    "\n",
    "    random.seed(1)  # Fixed seed for reproducibility\n",
    "    random.shuffle(train_csv_files)\n",
    "    selected_files = train_csv_files[:num]\n",
    "    # print(selected_files)\n",
    "\n",
    "    # random.seed(2)  # Fix random seed\n",
    "    # selected_files = random.sample(train_csv_files, num)\n",
    "    # print(selected_files)\n",
    "\n",
    "  \n",
    "    for file in selected_files:\n",
    "        file_path = os.path.join(train_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        train_data.append(df)\n",
    "    \n",
    "    # Merge all training data\n",
    "    train_df = pd.concat(train_data, ignore_index=True)\n",
    "    \n",
    "    # Load validation data while filtering out specified CPU power caps\n",
    "    validation_data = {}\n",
    "    for file in validation_csv_files:\n",
    "        file_path = os.path.join(validation_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "    \n",
    "        validation_data[file] = df\n",
    "    \n",
    "    # Drop any rows with missing values\n",
    "    train_df.dropna(inplace=True)\n",
    "    for key in validation_data:\n",
    "        validation_data[key].dropna(inplace=True)\n",
    "        \n",
    "    ############################# Step 2: Build MLP Model ############################# \n",
    "    \n",
    "    # Define feature columns and target column\n",
    "    # feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"IPS\", \"Memory Throughput\", \"LLC Misses\"]\n",
    "    feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "    # feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\"]\n",
    "    \n",
    "    target_col = \"Performance\"\n",
    "    \n",
    "    # Extract features and target for training\n",
    "    X_train = train_df[feature_cols].values\n",
    "    y_train = train_df[target_col].values.reshape(-1, 1)\n",
    "    \n",
    "    # Normalize features and target\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    \n",
    "    # Build the improved MLP model\n",
    "    # Define the MLP model properly\n",
    "    # gpu: relu x2, selu x2\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(X_train_scaled.shape[1],)),  # Explicitly define input shape\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(64, activation='selu'),\n",
    "        Dense(32, activation='selu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    # ############################# Step 3: Train MLP Model #############################\n",
    "    # # Compile the model with a different optimizer\n",
    "    # model.compile(optimizer='nadam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # # Train the model\n",
    "    # history = model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=3)\n",
    "    \n",
    "    # # Save the trained model\n",
    "    # model.save(os.path.join(save_model_dir, f\"performance_prediction_model_gpu_{num}.h5\"))\n",
    "\n",
    "    \n",
    "    ############################# Step 5: Populate Initial Performance Matrix ############################# \n",
    "    \n",
    "    # model_path = os.path.join(save_model_dir, f\"performance_prediction_model_gpu_{num}.h5\")  # Legacy format\n",
    "    model_path = os.path.join(save_model_dir, f\"performance_prediction_model_gpu.h5\")  # Legacy format\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path, custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
    "    # feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"IPS\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "    feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "    \n",
    "    target_col = \"Performance\"\n",
    "    \n",
    "    # Dictionary to store application data\n",
    "    app_data = {}\n",
    "\n",
    "    # Now directly process train_data instead of reloading CSVs\n",
    "    for df in train_data:\n",
    "        # Extract the application name from the filename stored during loading\n",
    "        app_name = df[\"Application\"].iloc[0] if \"Application\" in df.columns else \"unknown_app\"\n",
    "\n",
    "        # Keep only required columns\n",
    "        required_columns = [\"CPU Power Cap\", \"GPU Power Cap\", \"Performance\"]\n",
    "        df = df[required_columns]\n",
    "\n",
    "        # Create a unique power pair column\n",
    "        df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
    "\n",
    "        # Store application data\n",
    "        app_data[app_name] = df[[\"Power Pair\", \"Performance\"]].set_index(\"Power Pair\")\n",
    "\n",
    "    # Combine all applications into a single 2D matrix\n",
    "    performance_matrix = pd.DataFrame(\n",
    "        index=sorted(set().union(*[df.index for df in app_data.values()])),\n",
    "        columns=sorted(app_data.keys())\n",
    "    )\n",
    "\n",
    "    # Populate the performance matrix with training data\n",
    "    for app_name, df in app_data.items():\n",
    "        performance_matrix[app_name] = df[\"Performance\"]\n",
    "    \n",
    "    \n",
    "    # np.random.seed(1)  # fix seed\n",
    "    # n = num\n",
    "    # selected_apps = np.random.choice(performance_matrix.columns, size=n, replace=False)\n",
    "    # performance_matrix_selected = performance_matrix[selected_apps]\n",
    "    \n",
    "    performance_matrix_selected = performance_matrix\n",
    "\n",
    "    # n = num\n",
    "    # selected_apps = performance_matrix.columns[:n]  # Select first n apps directly\n",
    "    # performance_matrix_selected = performance_matrix[selected_apps]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################# Step 6: Construct Sparse Matrix and Predict Missing Value ############################# \n",
    "    \n",
    "    # Directories\n",
    "    # save_model_dir = \"./MLP_model/\"\n",
    "    os.makedirs(save_model_dir, exist_ok=True)\n",
    "    \n",
    "    # Results storage\n",
    "    nn_results = []\n",
    "    cf_results = []\n",
    "    \n",
    "    # Process each new application\n",
    "    for file in validation_csv_files:\n",
    "        file_path = os.path.join(validation_dir, file)\n",
    "        new_app_name = file.replace(\"_performance.csv\", \"\")\n",
    "    \n",
    "        # Load validation data\n",
    "        df_new = pd.read_csv(file_path)\n",
    "        df_new[\"Power Pair\"] = list(zip(df_new[\"CPU Power Cap\"], df_new[\"GPU Power Cap\"]))\n",
    "    \n",
    "        # Add new application to performance matrix\n",
    "        performance_matrix_selected[new_app_name] = np.nan\n",
    "    \n",
    "        #############  Predict 20% of power pairs using trained NN --- Construct Sparse Matrix  ############# \n",
    "        \n",
    "        df_sampled = df_new.sample(frac=0.2, random_state=seed)  # Select 20% of rows\n",
    "        sampled_pairs = df_sampled[\"Power Pair\"].unique()\n",
    "    \n",
    "        true_values, nn_predicted_values = [], []\n",
    "        for power_pair in sampled_pairs:\n",
    "            X_sample = df_new[df_new[\"Power Pair\"] == power_pair][feature_cols].values\n",
    "            X_sample_scaled = scaler_X.transform(X_sample)\n",
    "            \n",
    "            # Predict performance\n",
    "            y_pred = model.predict(X_sample_scaled)\n",
    "            predicted_value = scaler_y.inverse_transform(y_pred)[0][0]\n",
    "        \n",
    "            # Fill performance matrix with NN predictions\n",
    "            performance_matrix_selected.at[power_pair, new_app_name] = predicted_value\n",
    "    \n",
    "            # Store true and predicted values for error calculation\n",
    "            if power_pair in df_new.set_index(\"Power Pair\").index:\n",
    "                actual = df_new.loc[df_new[\"Power Pair\"] == power_pair, \"Performance\"].values[0]\n",
    "                true_values.append(actual)\n",
    "                nn_predicted_values.append(predicted_value)\n",
    "        \n",
    "        ############## Compute NN Prediction Accuracy ##############\n",
    "    \n",
    "        true_values = np.array(true_values)\n",
    "        nn_predicted_values = np.array(nn_predicted_values)\n",
    "        \n",
    "        nn_mae = mean_absolute_error(true_values, nn_predicted_values)\n",
    "        nn_rmse = np.sqrt(mean_squared_error(true_values, nn_predicted_values))\n",
    "        nn_r2 = r2_score(true_values, nn_predicted_values)\n",
    "        \n",
    "        # Percentage-Based Prediction Error\n",
    "        relative_errors = np.abs((true_values - nn_predicted_values) / true_values) * 100\n",
    "        nn_pred_error = np.mean(relative_errors)\n",
    "        \n",
    "        # 95% Confidence Interval for Prediction Accuracy\n",
    "        confidence = 0.98\n",
    "        n = len(relative_errors)\n",
    "        std_err = stats.sem(relative_errors)  # Standard error of the mean\n",
    "        h = std_err * stats.t.ppf((1 + confidence) / 2., n-1)  # Margin of error\n",
    "        \n",
    "        # The accuracy is (100 - pred_error)\n",
    "        nn_accuracy = 100 - nn_pred_error\n",
    "        nn_accuracy_ci_low = nn_accuracy - h\n",
    "        nn_accuracy_ci_high = nn_accuracy + h\n",
    "        \n",
    "        # Save results, now including CI\n",
    "        nn_results.append((new_app_name, nn_mae, nn_rmse, nn_r2, nn_pred_error, nn_accuracy_ci_low, nn_accuracy_ci_high))\n",
    "    \n",
    "        print(f\"NN Prediction for {new_app_name}: MAE={nn_mae:.4f}, Prediction Accuracy={100 - nn_pred_error:.2f}%\")\n",
    "    \n",
    "        ##############  Train Neural CF  ##############\n",
    "        power_pair_map = {pair: i for i, pair in enumerate(performance_matrix_selected.index)}\n",
    "        app_map = {app: i for i, app in enumerate(performance_matrix_selected.columns)}\n",
    "    \n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for app in performance_matrix_selected.columns:\n",
    "            for power_pair in performance_matrix_selected.index:\n",
    "                if not np.isnan(performance_matrix_selected.at[power_pair, app]):\n",
    "                    train_data.append([power_pair_map[power_pair], app_map[app]])\n",
    "                    train_labels.append(performance_matrix_selected.at[power_pair, app])\n",
    "    \n",
    "        train_data = np.array(train_data)\n",
    "        train_labels = np.array(train_labels)\n",
    "    \n",
    "        # Define Neural CF Model\n",
    "        num_power_pairs = len(power_pair_map)\n",
    "        num_apps = len(app_map)\n",
    "        latent_dim = 10  # Embedding size\n",
    "    \n",
    "        input_power_pair = Input(shape=(1,))\n",
    "        input_app = Input(shape=(1,))\n",
    "    \n",
    "        power_embedding = Embedding(num_power_pairs, latent_dim)(input_power_pair)\n",
    "        app_embedding = Embedding(num_apps, latent_dim)(input_app)\n",
    "    \n",
    "        power_vec = Flatten()(power_embedding)\n",
    "        app_vec = Flatten()(app_embedding)\n",
    "    \n",
    "        merged = Concatenate()([power_vec, app_vec])\n",
    "        dense_0 = Dense(256, activation='relu')(merged)\n",
    "        dense_1 = Dense(128, activation='relu')(dense_0)\n",
    "        dense_2 = Dense(64, activation='selu')(dense_1)\n",
    "        dense_3 = Dense(32, activation='selu')(dense_2)\n",
    "        output = Dense(1, activation='linear')(dense_3)\n",
    "    \n",
    "        ncf_model = Model(inputs=[input_power_pair, input_app], outputs=output)\n",
    "        ncf_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "        ncf_model.fit([train_data[:, 0], train_data[:, 1]], train_labels, epochs=25, batch_size=32, verbose=3)\n",
    "    \n",
    "        ##############  Predict Missing Value via NCF  ##############\n",
    "        for power_pair in performance_matrix_selected.index:\n",
    "            if np.isnan(performance_matrix_selected.at[power_pair, new_app_name]):\n",
    "                power_idx = power_pair_map[power_pair]\n",
    "                app_idx = app_map[new_app_name]\n",
    "                pred_value = ncf_model.predict([np.array([power_idx]), np.array([app_idx])])[0][0]\n",
    "                performance_matrix_selected.at[power_pair, new_app_name] = pred_value\n",
    "    \n",
    "        ############### Compute CF Prediction Accuracy ##############\n",
    "        true_values = df_new.set_index(\"Power Pair\")[\"Performance\"]\n",
    "        predicted_values = performance_matrix_selected[new_app_name].reindex(true_values.index)\n",
    "        \n",
    "        cf_mae = mean_absolute_error(true_values, predicted_values)\n",
    "        cf_rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "        cf_r2 = r2_score(true_values, predicted_values)\n",
    "        \n",
    "        # Percentage-Based Prediction Error\n",
    "        relative_errors = np.abs((true_values - predicted_values) / true_values) * 100\n",
    "        cf_pred_error = np.mean(relative_errors)\n",
    "        \n",
    "        # 95% Confidence Interval for Prediction Accuracy\n",
    "        \n",
    "        n = len(relative_errors)\n",
    "        std_err = stats.sem(relative_errors)  # Standard error of the mean\n",
    "        h = std_err * stats.t.ppf((1 + confidence) / 2., n-1)  # Margin of error\n",
    "        \n",
    "        \n",
    "        # The accuracy is (100 - pred_error)\n",
    "        cf_accuracy = 100 - cf_pred_error\n",
    "        cf_accuracy_ci_low = cf_accuracy - h\n",
    "        cf_accuracy_ci_high = cf_accuracy + h\n",
    "        \n",
    "        # Save results including CI\n",
    "        cf_results.append((new_app_name, cf_mae, cf_rmse, cf_r2, cf_pred_error, cf_accuracy_ci_low, cf_accuracy_ci_high))\n",
    "    \n",
    "        print(f\"NCF Prediction for {new_app_name}: MAE={cf_mae:.4f}, Prediction Accuracy={100 - cf_pred_error:.2f}%\")\n",
    "    \n",
    "    # Convert results into a DataFrame and display\n",
    "    nn_results_df = pd.DataFrame(nn_results, columns=[\"Application\", \"MAE\", \"RMSE\", \"R²\", \"Prediction Error (%)\", \"CI Low\", \"CI High\"])\n",
    "    cf_results_df = pd.DataFrame(cf_results, columns=[\"Application\", \"MAE\", \"RMSE\", \"R²\", \"Prediction Error (%)\", \"CI Low\", \"CI High\"])\n",
    "\n",
    "\n",
    "    return nn_results_df, cf_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "678908c5-e99e-43dd-bfbf-9dc968387599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "NN Prediction for bert_large: MAE=0.0270, Prediction Accuracy=97.13%\n",
      "Epoch 1/25\n",
      "Epoch 2/25\n",
      "Epoch 3/25\n",
      "Epoch 4/25\n",
      "Epoch 5/25\n",
      "Epoch 6/25\n",
      "Epoch 7/25\n",
      "Epoch 8/25\n",
      "Epoch 9/25\n",
      "Epoch 10/25\n",
      "Epoch 11/25\n",
      "Epoch 12/25\n",
      "Epoch 13/25\n",
      "Epoch 14/25\n",
      "Epoch 15/25\n",
      "Epoch 16/25\n",
      "Epoch 17/25\n",
      "Epoch 18/25\n",
      "Epoch 19/25\n",
      "Epoch 20/25\n",
      "Epoch 21/25\n",
      "Epoch 22/25\n",
      "Epoch 23/25\n",
      "Epoch 24/25\n",
      "Epoch 25/25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "NCF Prediction for bert_large: MAE=0.0643, Prediction Accuracy=92.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
      "/tmp/ipykernel_1373292/3316900791.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "NN Prediction for bert_large: MAE=0.0337, Prediction Accuracy=96.42%\n",
      "Epoch 1/25\n",
      "Epoch 2/25\n",
      "Epoch 3/25\n",
      "Epoch 4/25\n",
      "Epoch 5/25\n",
      "Epoch 6/25\n",
      "Epoch 7/25\n",
      "Epoch 8/25\n",
      "Epoch 9/25\n",
      "Epoch 10/25\n",
      "Epoch 11/25\n",
      "Epoch 12/25\n",
      "Epoch 13/25\n",
      "Epoch 14/25\n",
      "Epoch 15/25\n",
      "Epoch 16/25\n",
      "Epoch 17/25\n",
      "Epoch 18/25\n",
      "Epoch 19/25\n",
      "Epoch 20/25\n",
      "Epoch 21/25\n",
      "Epoch 22/25\n",
      "Epoch 23/25\n",
      "Epoch 24/25\n",
      "Epoch 25/25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "NCF Prediction for bert_large: MAE=0.0665, Prediction Accuracy=92.34%\n"
     ]
    }
   ],
   "source": [
    "benchmarks = [\"NAMD\", \"bert_large\", \"lammps\", \"miniGAN\", \"Resnet50\", \n",
    "        \"sw4lite\", \"UNet\", \"gromacs\",\"XSBench\",\"CRADL\",\"Laghos\"]\n",
    "\n",
    "\n",
    "benchmarks = [\"bert_large\"]\n",
    "\n",
    "\n",
    "nums = [1,8,16]\n",
    "nums=[8,16]\n",
    "\n",
    "ncf_accuracy_results = {}  # Initialize first\n",
    "\n",
    "for num in nums:\n",
    "    for app in benchmarks:\n",
    "        nn_results_df, cf_results_df = test(num, app)\n",
    "        \n",
    "        # Assume cf_results_df has the correct columns\n",
    "        app_name = cf_results_df.iloc[0]['Application']\n",
    "        pred_error = cf_results_df.iloc[0]['Prediction Error (%)']\n",
    "        ci_low = cf_results_df.iloc[0]['CI Low']\n",
    "        ci_high = cf_results_df.iloc[0]['CI High']\n",
    "\n",
    "        ncf_accuracy = 100 - pred_error\n",
    "\n",
    "        if app_name not in ncf_accuracy_results:\n",
    "            ncf_accuracy_results[app_name] = {}\n",
    "\n",
    "        ncf_accuracy_results[app_name][num] = {\n",
    "            \"mean\": ncf_accuracy,\n",
    "            \"ci_low\": ci_low,\n",
    "            \"ci_high\": ci_high\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7789aa-acab-446b-8d3d-70cf52169e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NCF Prediction Accuracy with 98% Confidence Interval ===\n",
      "Application         NCF-8                             NCF-16                            \n",
      "--------------------------------------------------------------------------------\n",
      "bert_large          92.52% [90.69%, 94.35%]       92.34% [90.60%, 94.08%]       \n"
     ]
    }
   ],
   "source": [
    "ncf_accuracy_df = pd.DataFrame.from_dict(ncf_accuracy_results, orient='index')\n",
    "ncf_accuracy_df = ncf_accuracy_df[nums]\n",
    "\n",
    "print(\"\\n=== NCF Prediction Accuracy with 98% Confidence Interval ===\")\n",
    "print(f\"{'Application':<20}\" + \"\".join([f\"NCF-{num:<30}\" for num in nums]))\n",
    "print(\"-\" * (20 + 30 * len(nums)))\n",
    "\n",
    "for app, row in ncf_accuracy_df.iterrows():\n",
    "    print(f\"{app:<20}\", end=\"\")\n",
    "    for num in nums:\n",
    "        acc_info = row[num]\n",
    "        if pd.isna(acc_info):\n",
    "            print(f\"{'-':<30}\", end=\"\")\n",
    "        else:\n",
    "            mean_acc = acc_info[\"mean\"]\n",
    "            ci_low = acc_info[\"ci_low\"]\n",
    "            ci_high = acc_info[\"ci_high\"]\n",
    "            acc_str = f\"{mean_acc:.2f}% [{ci_low:.2f}%, {ci_high:.2f}%]\"\n",
    "            print(f\"{acc_str:<30}\", end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4687612-0219-4644-a87a-50f9cb416fae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bfs</th>\n",
       "      <th>cfd</th>\n",
       "      <th>cfd_double</th>\n",
       "      <th>fdtd2d</th>\n",
       "      <th>gemm</th>\n",
       "      <th>gups</th>\n",
       "      <th>kmeans</th>\n",
       "      <th>lavamd</th>\n",
       "      <th>maxflops</th>\n",
       "      <th>nw</th>\n",
       "      <th>...</th>\n",
       "      <th>Resnet50</th>\n",
       "      <th>sw4lite</th>\n",
       "      <th>Laghos</th>\n",
       "      <th>NAMD</th>\n",
       "      <th>miniGAN</th>\n",
       "      <th>gromacs</th>\n",
       "      <th>bert_large</th>\n",
       "      <th>UNet</th>\n",
       "      <th>CRADL</th>\n",
       "      <th>XSBench</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(120, 150)</th>\n",
       "      <td>0.637024</td>\n",
       "      <td>0.637359</td>\n",
       "      <td>0.818064</td>\n",
       "      <td>0.733109</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.970849</td>\n",
       "      <td>0.899788</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.716044</td>\n",
       "      <td>0.615326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748207</td>\n",
       "      <td>0.593205</td>\n",
       "      <td>0.645191</td>\n",
       "      <td>0.620911</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.684636</td>\n",
       "      <td>0.806175</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>0.640825</td>\n",
       "      <td>0.581656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 160)</th>\n",
       "      <td>0.601343</td>\n",
       "      <td>0.630359</td>\n",
       "      <td>0.843605</td>\n",
       "      <td>0.785478</td>\n",
       "      <td>0.636686</td>\n",
       "      <td>0.985136</td>\n",
       "      <td>0.899804</td>\n",
       "      <td>0.671545</td>\n",
       "      <td>0.753145</td>\n",
       "      <td>0.634912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>0.579719</td>\n",
       "      <td>0.640847</td>\n",
       "      <td>0.611251</td>\n",
       "      <td>0.696895</td>\n",
       "      <td>0.690649</td>\n",
       "      <td>0.823847</td>\n",
       "      <td>0.692480</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.594419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 170)</th>\n",
       "      <td>0.637012</td>\n",
       "      <td>0.630417</td>\n",
       "      <td>0.843523</td>\n",
       "      <td>0.845871</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>0.985148</td>\n",
       "      <td>0.918240</td>\n",
       "      <td>0.656853</td>\n",
       "      <td>0.773292</td>\n",
       "      <td>0.624922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756815</td>\n",
       "      <td>0.594429</td>\n",
       "      <td>0.642583</td>\n",
       "      <td>0.613256</td>\n",
       "      <td>0.725310</td>\n",
       "      <td>0.703670</td>\n",
       "      <td>0.829256</td>\n",
       "      <td>0.704401</td>\n",
       "      <td>0.640516</td>\n",
       "      <td>0.590241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 180)</th>\n",
       "      <td>0.632312</td>\n",
       "      <td>0.630321</td>\n",
       "      <td>0.870889</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>0.644969</td>\n",
       "      <td>0.985232</td>\n",
       "      <td>0.918253</td>\n",
       "      <td>0.633694</td>\n",
       "      <td>0.743598</td>\n",
       "      <td>0.615301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761961</td>\n",
       "      <td>0.588311</td>\n",
       "      <td>0.640753</td>\n",
       "      <td>0.590209</td>\n",
       "      <td>0.728197</td>\n",
       "      <td>0.712597</td>\n",
       "      <td>0.847633</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>0.640477</td>\n",
       "      <td>0.570782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 190)</th>\n",
       "      <td>0.637010</td>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.870746</td>\n",
       "      <td>0.916513</td>\n",
       "      <td>0.642902</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.918217</td>\n",
       "      <td>0.666623</td>\n",
       "      <td>0.743510</td>\n",
       "      <td>0.624946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757247</td>\n",
       "      <td>0.599265</td>\n",
       "      <td>0.646845</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.741272</td>\n",
       "      <td>0.717044</td>\n",
       "      <td>0.858999</td>\n",
       "      <td>0.712057</td>\n",
       "      <td>0.634252</td>\n",
       "      <td>0.559531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 210)</th>\n",
       "      <td>0.988398</td>\n",
       "      <td>0.983083</td>\n",
       "      <td>0.964160</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.970615</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984617</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>1.012247</td>\n",
       "      <td>0.991432</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>0.984795</td>\n",
       "      <td>0.977278</td>\n",
       "      <td>0.963588</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.978682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 220)</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.983148</td>\n",
       "      <td>0.964155</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>0.990035</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.978321</td>\n",
       "      <td>0.983114</td>\n",
       "      <td>0.975661</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002311</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.983839</td>\n",
       "      <td>0.953184</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>0.968834</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>0.962764</td>\n",
       "      <td>0.927079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 230)</th>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964168</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.995034</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.966676</td>\n",
       "      <td>0.975567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997511</td>\n",
       "      <td>0.922074</td>\n",
       "      <td>0.982641</td>\n",
       "      <td>0.952342</td>\n",
       "      <td>0.973780</td>\n",
       "      <td>0.964614</td>\n",
       "      <td>0.971409</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>0.948404</td>\n",
       "      <td>0.915300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 240)</th>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.983124</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.989992</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.983013</td>\n",
       "      <td>0.869468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986865</td>\n",
       "      <td>0.953991</td>\n",
       "      <td>1.009568</td>\n",
       "      <td>0.992875</td>\n",
       "      <td>0.950191</td>\n",
       "      <td>0.962752</td>\n",
       "      <td>0.976246</td>\n",
       "      <td>0.978114</td>\n",
       "      <td>0.947420</td>\n",
       "      <td>0.981660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 250)</th>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.983044</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>0.985166</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.966643</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998861</td>\n",
       "      <td>0.905228</td>\n",
       "      <td>0.980246</td>\n",
       "      <td>0.941115</td>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.957326</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.963974</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.917863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bfs       cfd  cfd_double    fdtd2d      gemm      gups  \\\n",
       "(120, 150)  0.637024  0.637359    0.818064  0.733109  0.638716  0.970849   \n",
       "(120, 160)  0.601343  0.630359    0.843605  0.785478  0.636686  0.985136   \n",
       "(120, 170)  0.637012  0.630417    0.843523  0.845871  0.642886  0.985148   \n",
       "(120, 180)  0.632312  0.630321    0.870889  0.879836  0.644969  0.985232   \n",
       "(120, 190)  0.637010  0.630438    0.870746  0.916513  0.642902  0.999798   \n",
       "...              ...       ...         ...       ...       ...       ...   \n",
       "(200, 210)  0.988398  0.983083    0.964160  0.999803  0.970615  0.999860   \n",
       "(200, 220)  0.999967  0.983148    0.964155  0.999816  0.990035  0.999869   \n",
       "(200, 230)  0.999982  1.000000    0.964168  0.999852  0.995034  0.999899   \n",
       "(200, 240)  0.999965  0.983124    0.999882  0.999814  0.989992  0.999878   \n",
       "(200, 250)  0.988516  0.983044    0.999986  0.999803  0.990102  0.985166   \n",
       "\n",
       "              kmeans    lavamd  maxflops        nw  ...  Resnet50   sw4lite  \\\n",
       "(120, 150)  0.899788  0.656863  0.716044  0.615326  ...  0.748207  0.593205   \n",
       "(120, 160)  0.899804  0.671545  0.753145  0.634912  ...  0.763345  0.579719   \n",
       "(120, 170)  0.918240  0.656853  0.773292  0.624922  ...  0.756815  0.594429   \n",
       "(120, 180)  0.918253  0.633694  0.743598  0.615301  ...  0.761961  0.588311   \n",
       "(120, 190)  0.918217  0.666623  0.743510  0.624946  ...  0.757247  0.599265   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "(200, 210)  0.999771  0.999971  1.000000  0.999959  ...  0.984617  0.986726   \n",
       "(200, 220)  0.999768  0.978321  0.983114  0.975661  ...  1.002311  0.945251   \n",
       "(200, 230)  1.000000  0.999954  0.966676  0.975567  ...  0.997511  0.922074   \n",
       "(200, 240)  0.999878  0.988977  0.983013  0.869468  ...  0.986865  0.953991   \n",
       "(200, 250)  0.999806  0.988977  0.966643  0.952318  ...  0.998861  0.905228   \n",
       "\n",
       "              Laghos      NAMD   miniGAN   gromacs  bert_large      UNet  \\\n",
       "(120, 150)  0.645191  0.620911  0.679260  0.684636    0.806175  0.686133   \n",
       "(120, 160)  0.640847  0.611251  0.696895  0.690649    0.823847  0.692480   \n",
       "(120, 170)  0.642583  0.613256  0.725310  0.703670    0.829256  0.704401   \n",
       "(120, 180)  0.640753  0.590209  0.728197  0.712597    0.847633  0.714047   \n",
       "(120, 190)  0.646845  0.587302  0.741272  0.717044    0.858999  0.712057   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "(200, 210)  1.012247  0.991432  0.990818  0.984795    0.977278  0.963588   \n",
       "(200, 220)  0.983839  0.953184  0.972923  0.968834    0.973787  0.963600   \n",
       "(200, 230)  0.982641  0.952342  0.973780  0.964614    0.971409  0.946061   \n",
       "(200, 240)  1.009568  0.992875  0.950191  0.962752    0.976246  0.978114   \n",
       "(200, 250)  0.980246  0.941115  0.938624  0.957326    0.971000  0.963974   \n",
       "\n",
       "               CRADL   XSBench  \n",
       "(120, 150)  0.640825  0.581656  \n",
       "(120, 160)  0.634400  0.594419  \n",
       "(120, 170)  0.640516  0.590241  \n",
       "(120, 180)  0.640477  0.570782  \n",
       "(120, 190)  0.634252  0.559531  \n",
       "...              ...       ...  \n",
       "(200, 210)  0.982609  0.978682  \n",
       "(200, 220)  0.962764  0.927079  \n",
       "(200, 230)  0.948404  0.915300  \n",
       "(200, 240)  0.947420  0.981660  \n",
       "(200, 250)  0.959275  0.917863  \n",
       "\n",
       "[99 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_matrix_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0284b39c-2cd1-4d1a-abd2-2a4495869e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix_selected.to_csv(\"./prediction_res/performance_matrix_cpu.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d11c78-d840-4486-9230-c047262e407d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "835f1a0a-7433-4aed-8a08-d7f726bb09cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed found: 27\n",
      "Shuffled list: ['gups_performance.csv', 'knn_performance.csv', 'bfs_performance.csv', 'zmddft_performance.csv', 'kalman_performance.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_seed_for_gups_first(train_dir):\n",
    "    train_csv_files = [f for f in os.listdir(train_dir) if f.endswith(\".csv\")]\n",
    "    original_files = list(train_csv_files)  # keep a copy for resetting\n",
    "    \n",
    "    target_file = \"gups_performance.csv\"\n",
    "    max_attempts = 100000\n",
    "\n",
    "    for seed in range(0, max_attempts):\n",
    "        train_csv_files = list(original_files)  # reset list\n",
    "        random.seed(seed)\n",
    "        random.shuffle(train_csv_files)\n",
    "        if train_csv_files[0] == target_file:\n",
    "            print(f\"Seed found: {seed}\")\n",
    "            print(f\"Shuffled list: {train_csv_files[:5]}\")\n",
    "            return seed\n",
    "\n",
    "    print(\"No matching seed found in range.\")\n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "train_dir = \"./altis_power_cap_res/runs/train\"\n",
    "find_seed_for_gups_first(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c9027-b7fe-4485-81f1-e67dd504e0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
