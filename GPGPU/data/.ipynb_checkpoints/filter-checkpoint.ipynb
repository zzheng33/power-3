{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020daebb-ccf5-43ec-88f4-a9ec11a5e9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200_180 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_190 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_250 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_200 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_190 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_150 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_230 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_220 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_210 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_220 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_150 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_180 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_250 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_220 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_240 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_200 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_240 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_250 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_210 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_220 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_160 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_190 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_220 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_160 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_170 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_180 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_230 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_230 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_160 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_200 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_180 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_250 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_150 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_220 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_180 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_230 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_200 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_240 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_200 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_190 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_210 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_240 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_210 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_230 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_210 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_250 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_150 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_170 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_160 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_250 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_180 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_210 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_240 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_210 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_150 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_200 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_170 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_250 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_240 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_180 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_220 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_170 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_230 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_160 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_200 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_160 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_190 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_190 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 160_150 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 180_160 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_170 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 200_190 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_240 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 190_150 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 150_230 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 140_170 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Processed 170_170 and saved in ./ecp_power_cap_res/runs/run1/UNet\n",
      "Input directory ./ecp_power_cap_res/runs/run1/gromacs/unfiltered/ does not exist, skipping gromacs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Benchmarks list\n",
    "benchmarks = [\"bert_large\", \"Resnet50\", \"UNet\", \"CRADL\",\"gromacs\",\"miniGAN\"]\n",
    "benchmarks = [\"Resnet50\", \"UNet\"]\n",
    "# benchmarks = [\"NAMD\"]\n",
    "\n",
    "\n",
    "run_id = 1\n",
    "# Base input directory structure\n",
    "input_base_dir = f\"./ecp_power_cap_res/runs/run{run_id}/{{}}/unfiltered/\"\n",
    "input_base_dir = f\"./A30/ecp_power_cap_res/runs/run{run_id}/{{}}/unfiltered/\"\n",
    "\n",
    "\n",
    "# Output base directory\n",
    "\n",
    "output_base_dir = f\"./ecp_power_cap_res/runs/run{run_id}/\"\n",
    "output_base_dir = f\"./A30/ecp_power_cap_res/runs/run{run_id}/\"\n",
    "\n",
    "\n",
    "# Ensure output directories exist\n",
    "for benchmark in benchmarks:\n",
    "    os.makedirs(os.path.join(output_base_dir, benchmark), exist_ok=True)\n",
    "\n",
    "def process_csv_files(cpu_power, gpu_power, app_name, input_dir):\n",
    "    \"\"\"Process CSV files for a given CPU and GPU power combination.\"\"\"\n",
    "    prefix = f\"{cpu_power}_{gpu_power}\"\n",
    "    \n",
    "    # File paths\n",
    "    gpu_metrics_file = os.path.join(input_dir, f\"{prefix}_gpu_metrics.csv\")\n",
    "    cpu_power_file = os.path.join(input_dir, f\"{prefix}_cpu_power.csv\")\n",
    "    cpu_metrics_file = os.path.join(input_dir, f\"{prefix}_cpu_metrics.csv\")\n",
    "\n",
    "    # Output directory\n",
    "    output_dir = os.path.join(output_base_dir, app_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Read GPU metrics\n",
    "    df_gpu = pd.read_csv(gpu_metrics_file)\n",
    "    if app_name == \"UNet\":\n",
    "        count = 5\n",
    "    elif app_name == \"gromacs\":\n",
    "        count = 1\n",
    "    elif app_name == \"miniGAN\":\n",
    "        count = 1\n",
    "    else:\n",
    "        count = 15\n",
    "    # Find first row where FP16 Active + FP32 Active + FP64 Active > 0 for 20 continuous rows\n",
    "    fp_active = df_gpu[\"FP16 Active\"] + df_gpu[\"FP32 Active\"] + df_gpu[\"FP64 Active\"]\n",
    "    for i in range(len(fp_active) - count - 1):\n",
    "        if all(fp_active.iloc[i:i+count] > 0):\n",
    "            T = df_gpu.iloc[i][\"Time (s)\"]\n",
    "            df_gpu = df_gpu.iloc[i:].copy()  # Keep rows from T onward\n",
    "            df_gpu[\"Time (s)\"] -= T  # Normalize time\n",
    "            break\n",
    "    else:\n",
    "        print(f\"No valid GPU activity found for {prefix}, skipping.\")\n",
    "        return\n",
    "\n",
    "    # Read CPU power and metrics\n",
    "    df_cpu_power = pd.read_csv(cpu_power_file)\n",
    "    df_cpu_metrics = pd.read_csv(cpu_metrics_file)\n",
    "\n",
    "    # Find nearest timestamp in CPU power and metrics files\n",
    "    T_cpu_power = df_cpu_power[\"Time (s)\"].sub(T).abs().idxmin()\n",
    "    T_cpu_metrics = df_cpu_metrics[\"Time (s)\"].sub(T).abs().idxmin()\n",
    "\n",
    "    # Process CPU power file\n",
    "    df_cpu_power = df_cpu_power.iloc[T_cpu_power:].copy()\n",
    "    df_cpu_power[\"Time (s)\"] -= df_cpu_power.iloc[0][\"Time (s)\"]\n",
    "\n",
    "    # Process CPU metrics file\n",
    "    df_cpu_metrics = df_cpu_metrics.iloc[T_cpu_metrics:].copy()\n",
    "    df_cpu_metrics[\"Time (s)\"] -= df_cpu_metrics.iloc[0][\"Time (s)\"]\n",
    "\n",
    "    # Save processed files\n",
    "    df_gpu.to_csv(os.path.join(output_dir, f\"{prefix}_gpu_metrics.csv\"), index=False)\n",
    "    df_cpu_power.to_csv(os.path.join(output_dir, f\"{prefix}_cpu_power.csv\"), index=False)\n",
    "    df_cpu_metrics.to_csv(os.path.join(output_dir, f\"{prefix}_cpu_metrics.csv\"), index=False)\n",
    "\n",
    "    print(f\"Processed {prefix} and saved in {output_dir}\")\n",
    "\n",
    "# Iterate over specified benchmarks\n",
    "for benchmark in benchmarks:\n",
    "    input_dir = input_base_dir.format(benchmark)\n",
    "    \n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist, skipping {benchmark}.\")\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if \"_gpu_metrics.csv\" in filename:\n",
    "            parts = filename.split(\"_\")\n",
    "            cpu_power, gpu_power = parts[0], parts[1]\n",
    "            process_csv_files(cpu_power, gpu_power, benchmark, input_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "785c6eeb-d305-47fd-99ba-34b9d067d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Base directory where run folders are located\n",
    "base_dir = \"./ecp_power_cap_res/runs/\"\n",
    "\n",
    "# Define the runs and application names\n",
    "runs = [\"run1\", \"run2\", \"run3\", \"run4\", \"run5\"]\n",
    "apps = [\"bert_large\", \"Resnet50\", \"UNet\", \"CRADL\", \"gromacs\", \"miniGAN\",\"NAMD\"]\n",
    "apps = [\"NAMD\"]\n",
    "\n",
    "# Traverse each run and app directory\n",
    "for run in runs:\n",
    "    for app in apps:\n",
    "        app_path = os.path.join(base_dir, run, app)\n",
    "        unfiltered_path = os.path.join(app_path, \"unfiltered\")\n",
    "\n",
    "        if os.path.isdir(app_path):\n",
    "            os.makedirs(unfiltered_path, exist_ok=True)\n",
    "\n",
    "            # Move all CSV files to the unfiltered folder\n",
    "            for file in os.listdir(app_path):\n",
    "                if file.endswith(\".csv\"):\n",
    "                    src = os.path.join(app_path, file)\n",
    "                    dst = os.path.join(unfiltered_path, file)\n",
    "                    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a268b271-5b51-41a2-a5fe-2cbd91a07186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200_180 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_190 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_250 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_200 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_190 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_150 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_230 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_220 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_210 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_220 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_150 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_180 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_250 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_220 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_240 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_200 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_240 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_250 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_210 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_220 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_160 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_190 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_220 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_160 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_170 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_180 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_230 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_230 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_160 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_200 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_180 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_250 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_150 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_220 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_180 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_230 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_200 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_240 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_200 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_190 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_210 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_240 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_210 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_230 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_210 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_250 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_150 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_170 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_160 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_250 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_180 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_210 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_240 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_210 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_150 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_200 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_170 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_250 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_240 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_180 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_220 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_170 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_230 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_160 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_200 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_160 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_190 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_190 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 160_150 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 180_160 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_170 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_190 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_240 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 190_150 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 150_230 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 140_170 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 170_170 -> ./ecp_power_cap_res/runs/run5/NAMD\n",
      "Processed 200_180 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_190 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_250 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_200 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_190 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_150 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_230 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_220 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_210 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_220 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_150 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_180 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_250 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_220 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_240 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_200 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_240 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_250 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_210 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_220 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_160 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_190 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_220 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_160 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_170 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_180 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_230 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_230 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_160 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_200 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_180 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_250 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_150 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_220 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_180 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_230 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_200 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_240 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_200 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_190 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_210 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_240 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_210 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_230 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_210 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_250 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_150 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_170 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_160 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_250 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_180 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_210 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_240 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_210 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_150 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_200 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_170 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_250 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_240 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_180 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_220 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_170 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_230 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_160 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_200 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_160 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_190 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_190 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 160_150 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 180_160 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_170 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 200_190 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_240 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 190_150 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 150_230 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 140_170 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Processed 170_170 -> ./ecp_power_cap_res/runs/run2/NAMD\n",
      "Missing unfiltered dir: ./ecp_power_cap_res/runs/validation/NAMD/unfiltered, skipping.\n",
      "Processed 200_180 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_190 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_250 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_200 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_190 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_150 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_230 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_220 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_210 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_220 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_150 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_180 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_250 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_220 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_240 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_200 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_240 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_250 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_210 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_220 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_160 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_190 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_220 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_160 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_170 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_180 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_230 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_230 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_160 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_200 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_180 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_250 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_150 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_220 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_180 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_230 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_200 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_240 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_200 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_190 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_210 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_240 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_210 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_230 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_210 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_250 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_150 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_170 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_160 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_250 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_180 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_210 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_240 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_210 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_150 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_200 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_170 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_250 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_240 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_180 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_220 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_170 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_230 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_160 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_200 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_160 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_190 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_190 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 160_150 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 180_160 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_170 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_190 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_240 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 190_150 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 150_230 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 140_170 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 170_170 -> ./ecp_power_cap_res/runs/run4/NAMD\n",
      "Processed 200_180 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_190 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_250 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_200 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_190 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_150 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_230 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_220 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_210 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_220 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_150 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_180 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_250 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_220 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_240 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_200 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_240 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_250 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_210 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_220 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_160 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_190 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_220 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_160 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_170 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_180 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_230 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_230 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_160 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_200 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_180 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_250 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_150 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_220 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_180 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_230 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_200 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_240 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_200 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_190 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_210 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_240 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_210 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_230 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_210 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_250 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_150 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_170 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_160 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_250 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_180 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_210 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_240 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_210 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_150 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_200 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_170 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_250 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_240 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_180 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_220 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_170 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_230 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_160 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_200 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_160 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_190 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_190 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 160_150 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 180_160 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_170 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_190 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_240 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 190_150 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 150_230 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 140_170 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 170_170 -> ./ecp_power_cap_res/runs/run1/NAMD\n",
      "Processed 200_180 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_190 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_250 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_200 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_190 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_150 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_230 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_220 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_210 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_220 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_150 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_180 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_250 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_220 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_240 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_200 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_240 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_250 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_210 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_220 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_160 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_190 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_220 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_160 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_170 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_180 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_230 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_230 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_160 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_200 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_180 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_250 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_150 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_220 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_180 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_230 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_200 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_240 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_200 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_190 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_210 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_240 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_210 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_230 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_210 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_250 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_150 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_170 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_160 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_250 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_180 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_210 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_240 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_210 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_150 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_200 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_170 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_250 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_240 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_180 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_220 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_170 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_230 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_160 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_200 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_160 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_190 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_190 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 160_150 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 180_160 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_170 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 200_190 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_240 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 190_150 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 150_230 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 140_170 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Processed 170_170 -> ./ecp_power_cap_res/runs/run3/NAMD\n",
      "Missing unfiltered dir: ./ecp_power_cap_res/runs/.ipynb_checkpoints/NAMD/unfiltered, skipping.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Benchmarks list\n",
    "benchmarks = [\"bert_large\", \"Resnet50\", \"UNet\", \"CRADL\", \"gromacs\", \"miniGAN\"]\n",
    "benchmarks = [\"NAMD\"]\n",
    "\n",
    "\n",
    "# Base directory containing run folders\n",
    "base_run_dir = \"./ecp_power_cap_res/runs\"\n",
    "\n",
    "def process_csv_files(cpu_power, gpu_power, app_name, input_dir, output_dir):\n",
    "    \"\"\"Process CSV files for a given CPU and GPU power combination.\"\"\"\n",
    "    prefix = f\"{cpu_power}_{gpu_power}\"\n",
    "\n",
    "    # File paths\n",
    "    gpu_metrics_file = os.path.join(input_dir, f\"{prefix}_gpu_metrics.csv\")\n",
    "    cpu_power_file = os.path.join(input_dir, f\"{prefix}_cpu_power.csv\")\n",
    "    cpu_metrics_file = os.path.join(input_dir, f\"{prefix}_cpu_metrics.csv\")\n",
    "\n",
    "    # Check if files exist\n",
    "    if not all(os.path.exists(f) for f in [gpu_metrics_file, cpu_power_file, cpu_metrics_file]):\n",
    "        print(f\"Missing files for {prefix} in {input_dir}, skipping.\")\n",
    "        return\n",
    "\n",
    "    # Read GPU metrics\n",
    "    df_gpu = pd.read_csv(gpu_metrics_file)\n",
    "    if app_name == \"UNet\":\n",
    "        count = 5\n",
    "    elif app_name == \"gromacs\":\n",
    "        count = 1\n",
    "    elif app_name == \"miniGAN\":\n",
    "        count = 1\n",
    "    elif app_name == \"NAMD\":\n",
    "        count = 5\n",
    "    else:\n",
    "        count = 15\n",
    "\n",
    "    # Find first row with sustained GPU activity\n",
    "    fp_active = df_gpu[\"FP16 Active\"] + df_gpu[\"FP32 Active\"] + df_gpu[\"FP64 Active\"]\n",
    "    for i in range(len(fp_active) - count - 1):\n",
    "        if all(fp_active.iloc[i:i + count] > 0):\n",
    "            T = df_gpu.iloc[i][\"Time (s)\"]\n",
    "            df_gpu = df_gpu.iloc[i:].copy()\n",
    "            df_gpu[\"Time (s)\"] -= T\n",
    "            break\n",
    "    else:\n",
    "        print(f\"No valid GPU activity found for {prefix}, skipping.\")\n",
    "        return\n",
    "\n",
    "    # Read CPU power and metrics\n",
    "    df_cpu_power = pd.read_csv(cpu_power_file)\n",
    "    df_cpu_metrics = pd.read_csv(cpu_metrics_file)\n",
    "\n",
    "    # Align timestamps\n",
    "    T_cpu_power = df_cpu_power[\"Time (s)\"].sub(T).abs().idxmin()\n",
    "    T_cpu_metrics = df_cpu_metrics[\"Time (s)\"].sub(T).abs().idxmin()\n",
    "\n",
    "    df_cpu_power = df_cpu_power.iloc[T_cpu_power:].copy()\n",
    "    df_cpu_power[\"Time (s)\"] -= df_cpu_power.iloc[0][\"Time (s)\"]\n",
    "\n",
    "    df_cpu_metrics = df_cpu_metrics.iloc[T_cpu_metrics:].copy()\n",
    "    df_cpu_metrics[\"Time (s)\"] -= df_cpu_metrics.iloc[0][\"Time (s)\"]\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save processed files\n",
    "    df_gpu.to_csv(os.path.join(output_dir, f\"{prefix}_gpu_metrics.csv\"), index=False)\n",
    "    df_cpu_power.to_csv(os.path.join(output_dir, f\"{prefix}_cpu_power.csv\"), index=False)\n",
    "    df_cpu_metrics.to_csv(os.path.join(output_dir, f\"{prefix}_cpu_metrics.csv\"), index=False)\n",
    "\n",
    "    print(f\"Processed {prefix} -> {output_dir}\")\n",
    "\n",
    "# Walk through each run and benchmark\n",
    "for run_name in os.listdir(base_run_dir):\n",
    "    run_path = os.path.join(base_run_dir, run_name)\n",
    "    if not os.path.isdir(run_path):\n",
    "        continue\n",
    "\n",
    "    for benchmark in benchmarks:\n",
    "        input_dir = os.path.join(run_path, benchmark, \"unfiltered\")\n",
    "        output_dir = os.path.join(run_path, benchmark)\n",
    "\n",
    "        if not os.path.exists(input_dir):\n",
    "            print(f\"Missing unfiltered dir: {input_dir}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(input_dir):\n",
    "            if \"_gpu_metrics.csv\" in filename:\n",
    "                parts = filename.split(\"_\")\n",
    "                cpu_power, gpu_power = parts[0], parts[1]\n",
    "                process_csv_files(cpu_power, gpu_power, benchmark, input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c47c0-735b-4241-9138-e36a76ad9d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
